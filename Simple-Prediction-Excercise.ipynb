{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import signal\n",
    "import pickle\n",
    "import pandas as pd\n",
    "#!pip install pandas_datareader\n",
    "from pandas_datareader import data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (22, 9)\n",
    "basket = ['EAT', 'TWTR', 'TTNP', 'SBUX', 'BAC', 'SHLDQ', 'STM', 'ACB', 'GREK']\n",
    "df = data.DataReader(basket, 'robinhood')\n",
    "df.head()\n",
    "orig = df.copy()\n",
    "\n",
    "df=df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scalers = {}\n",
    "y_scalers = {}\n",
    "for stock in basket:\n",
    "    for col in ('close_price', 'high_price', 'low_price', 'open_price', 'volume'):\n",
    "        df[col] = df[col].astype(float)\n",
    "        df.loc[df['symbol'] == stock, col] = signal.detrend(df[df['symbol'] == stock][col])\n",
    "    df.loc[df['symbol'] == stock, 'mean_close_price_2'] = df.loc[df['symbol'] == stock, 'close_price'].rolling(window=2).mean()\n",
    "    df.loc[df['symbol'] == stock, 'mean_close_price_3'] = df.loc[df['symbol'] == stock, 'close_price'].rolling(window=3).mean()\n",
    "    df.loc[df['symbol'] == stock, 'std_close_price_2'] = df.loc[df['symbol'] == stock, 'close_price'].rolling(window=2).std()\n",
    "    df.loc[df['symbol'] == stock, 'std_close_price_3'] = df.loc[df['symbol'] == stock, 'close_price'].rolling(window=3).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scalers = {stock:{} for stock in basket}\n",
    "y_scalers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[df['symbol'] == 'EAT']['close_price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[df['symbol'] == 'TWTR']['close_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['tomo_gain'] = df['close_price'].shift(-1) - df['close_price']\n",
    "df['yday_gain'] = df['tomo_gain'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[df['symbol'] == 'EAT']['tomo_gain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[df['symbol'] == 'EAT'][:-1]['tomo_gain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "as_date = df['begins_at'].dt\n",
    "df['dayofweek'] = as_date.dayofweek\n",
    "df['quarter'] = as_date.quarter\n",
    "df['weekofyear'] = as_date.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['begins_at', 'interpolated', 'session'], axis=1)\n",
    "df = df.dropna(axis=0) # Due to window, first two rows now contain nans\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in basket:\n",
    "    df = df.drop(df.index[len(df[df['symbol'] == stock]) - 1], axis=0)\n",
    "    outliers = abs(df[df['symbol'] == stock]['tomo_gain']) < df[df['symbol'] == stock]['tomo_gain'].std() * 3\n",
    "    df[df['symbol'] == stock] = df[df['symbol'] == stock].loc[:, :][outliers]\n",
    "    df = df.drop(df[df['symbol'] == stock].iloc[-1].name) # get rid of last because next is a different stock\n",
    "    pre_y = df[df['symbol'] == stock]['tomo_gain'].values\n",
    "    y_scalers[stock] = make_pipeline(StandardScaler(), MinMaxScaler(feature_range=(-1, 1)))\n",
    "    for col in ('close_price', 'high_price', 'low_price', 'open_price', 'volume', 'mean_close_price_2', \\\n",
    "               'mean_close_price_3', 'std_close_price_2', 'std_close_price_3', 'yday_gain'):\n",
    "        pre_x = df[df['symbol'] == stock][col]\n",
    "        X_scalers[stock][col] = make_pipeline(StandardScaler(), MinMaxScaler(feature_range=(-1, 1)))\n",
    "        df.loc[df['symbol'] == stock, col] = X_scalers[stock][col].fit_transform(pre_x.values.reshape(-1,1))\n",
    "    df.loc[df['symbol'] == stock, 'tomo_gain'] = y_scalers[stock].fit_transform(pre_y.reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_scalers, open('x_scalers.pkl', 'wb'))\n",
    "pickle.dump(y_scalers, open('y_scalers.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( df.loc[df['symbol'] == basket[-1], 'tomo_gain'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['symbol'] == 'EAT'].describe()\n",
    "df.shape\n",
    "num_df_cols = df.shape[1] - 1 + len(basket) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(num_df_cols, input_shape=(1, num_df_cols)))\n",
    "model.add(tf.keras.layers.LSTM(64))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "model.add(tf.keras.layers.Dense(32, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['tomo_gain', 'symbol'], axis=1)\n",
    "y = df['tomo_gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['symbol'], columns=['symbol'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(X, dummies.values, axis=1)\n",
    "X.shape\n",
    "\n",
    "# Reshape to num_samples, timesteps, num_features\n",
    "X = np.reshape(X, (-1, 1, num_df_cols))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.values.reshape(-1,1), batch_size=64, epochs=1000, verbose=1)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.predict(X))\n",
    "model.save('market_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_scalers['EAT'].inverse_transform(model.predict(X[100:120])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_stock(symbol):\n",
    "    dumdums = np.zeros(len(basket))\n",
    "    dumdums[list(dummies.columns.values).index(symbol)] = 1.\n",
    "    return dumdums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_stock('TWTR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop()\n",
    "model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the 2 older dense layers\n",
    "model.layers[0].trainable = False\n",
    "model.layers[3].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(128, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_dfs = {}\n",
    "specific_models = {}\n",
    "for stock in basket:\n",
    "    basket_dfs[stock] = df[df['symbol'] == stock]\n",
    "    specific_models[stock] = tf.keras.models.clone_model(model)\n",
    "    specific_models[stock].set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_models['EAT'].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in basket:\n",
    "    specific_models[stock].compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xes = {}\n",
    "ys = {}\n",
    "for stock in basket:\n",
    "    repeated_dummies = pad_stock(stock).reshape(1,-1).repeat(len(basket_dfs[stock]),axis=0)\n",
    "    Xes[stock] = np.append(basket_dfs[stock].drop(['tomo_gain', 'symbol'], axis=1).values, repeated_dummies, axis=1)\n",
    "    Xes[stock] = np.reshape(Xes[stock], (-1, 1, num_df_cols))\n",
    "    ys[stock] = basket_dfs[stock]['tomo_gain'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xes_train, ys_train, Xes_test, ys_test, best_model_scores, best_model = {}, {}, {}, {}, {}, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in basket:\n",
    "    best_model_scores[stock] = 1e6\n",
    "for stock in basket:\n",
    "    Xes_train[stock] = Xes[stock][:-5]\n",
    "    ys_train[stock] = ys[stock][:-5]\n",
    "    Xes_test[stock] = Xes[stock][-5:]\n",
    "    ys_test[stock] = ys[stock][-5:]\n",
    "    for i in range(8):\n",
    "        specific_models[stock].fit(Xes_train[stock], ys_train[stock], batch_size=64, epochs=100, verbose=0)\n",
    "        specific_models[stock].fit(Xes_train[stock], ys_train[stock], batch_size=16, epochs=30, verbose=0)\n",
    "        specific_models[stock].fit(Xes_train[stock], ys_train[stock], batch_size=1, epochs=1, verbose=0)\n",
    "        evaluation = specific_models[stock].evaluate(Xes_test[stock], ys_test[stock])[0]\n",
    "        if evaluation < best_model_scores[stock]:\n",
    "            best_model_scores[stock] = evaluation\n",
    "            print('now saving {} because it was the best with eval score {}'.format(stock, evaluation))\n",
    "            best_model[stock] = tf.keras.models.clone_model(specific_models[stock])\n",
    "            best_model[stock].set_weights(specific_models[stock].get_weights())\n",
    "            best_model[stock].compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "        else:\n",
    "            print('did not save {} because it did not improve with eval score {}'.format(stock, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in basket:\n",
    "    specific_models[stock] = best_model[stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_scalers['TWTR'].inverse_transform(specific_models['TWTR'].predict(Xes['TWTR'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in basket:\n",
    "    plt.plot(y_scalers[stock].inverse_transform(specific_models[stock].predict(Xes[stock])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in basket:\n",
    "    today = df[df['symbol'] == stock].iloc[-1].drop(['tomo_gain', 'symbol'])\n",
    "    today = np.append(today, pad_stock(stock))\n",
    "    specific_models[stock].reset_states()\n",
    "    pred = specific_models[stock].predict(np.reshape(today, (-1, 1, num_df_cols)))\n",
    "    pred = y_scalers[stock].inverse_transform(pred)\n",
    "    print(\"Stock {}, pred: {}\".format(stock, np.asscalar(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock, model in specific_models.items():\n",
    "    model.save('finetuned_{}.h5'.format(stock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scalers = pickle.load(open('x_scalers.pkl', 'rb'))\n",
    "y_scalers = pickle.load(open('y_scalers.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_models = {}\n",
    "for stock in basket:\n",
    "    specific_models[stock] = tf.keras.models.load_model('finetuned_{}.h5'.format(stock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_day = data.DataReader(basket, 'robinhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_day.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_day = new_day.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in basket:\n",
    "    for col in ('close_price', 'high_price', 'low_price', 'open_price', 'volume'):\n",
    "        new_day[col] = new_day[col].astype(float)\n",
    "        new_day.loc[new_day['symbol'] == stock, col] = signal.detrend(new_day[new_day['symbol'] == stock][col])\n",
    "    new_day.loc[new_day['symbol'] == stock, 'mean_close_price_2'] = new_day.loc[new_day['symbol'] == stock, 'close_price'].rolling(window=2).mean()\n",
    "    new_day.loc[new_day['symbol'] == stock, 'mean_close_price_3'] = new_day.loc[new_day['symbol'] == stock, 'close_price'].rolling(window=3).mean()\n",
    "    new_day.loc[new_day['symbol'] == stock, 'std_close_price_2'] = new_day.loc[new_day['symbol'] == stock, 'close_price'].rolling(window=2).std()\n",
    "    new_day.loc[new_day['symbol'] == stock, 'std_close_price_3'] = new_day.loc[new_day['symbol'] == stock, 'close_price'].rolling(window=3).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_day['tomo_gain'] = new_day['close_price'].shift(-1) - new_day['close_price']\n",
    "new_day['yday_gain'] = new_day['tomo_gain'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_date = new_day['begins_at'].dt\n",
    "new_day['dayofweek'] = as_date.dayofweek\n",
    "new_day['quarter'] = as_date.quarter\n",
    "new_day['weekofyear'] = as_date.weekofyear\n",
    "new_day = new_day.drop(['begins_at', 'interpolated', 'session'], axis=1)\n",
    "new_day = new_day.dropna(axis=0)\n",
    "new_day = new_day.reset_index(drop=True)\n",
    "for stock in basket:\n",
    "    new_day = new_day.drop(new_day.index[len(new_day[new_day['symbol'] == stock]) - 1], axis=0)\n",
    "    outliers = abs(new_day[new_day['symbol'] == stock]['tomo_gain']) < new_day[new_day['symbol'] == stock]['tomo_gain'].std() * 3\n",
    "    new_day[new_day['symbol'] == stock] = new_day[new_day['symbol'] == stock].loc[:, :][outliers]\n",
    "    new_day = new_day.drop(new_day[new_day['symbol'] == stock].iloc[-1].name)\n",
    "    for col in ('close_price', 'high_price', 'low_price', 'open_price', 'volume', 'mean_close_price_2', \\\n",
    "               'mean_close_price_3', 'std_close_price_2', 'std_close_price_3', 'yday_gain'):\n",
    "        pre_x = new_day[new_day['symbol'] == stock][col]\n",
    "        new_day.loc[new_day['symbol'] == stock, col] = X_scalers[stock][col].transform(pre_x.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_day = new_day.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(new_day['symbol'], columns=['symbol'])\n",
    "num_df_cols = new_day.shape[1] - 1 + len(basket) - 1\n",
    "def pad_stock(symbol):\n",
    "    dumdums = np.zeros(len(basket))\n",
    "    dumdums[list(dummies.columns.values).index(symbol)] = 1.\n",
    "    return dumdums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in basket:\n",
    "    today = new_day[new_day['symbol'] == stock].iloc[-8:-1].drop(['tomo_gain', 'symbol'], axis=1)\n",
    "    today = np.append(today, pad_stock(stock).reshape(-1,9).repeat(7,axis=0))\n",
    "    specific_models[stock].reset_states()\n",
    "    pred = specific_models[stock].predict(np.reshape(today, (-1, 1, num_df_cols)))\n",
    "    pred = y_scalers[stock].inverse_transform(pred)\n",
    "    print(\"Stock {}, pred: {}\".format(stock, np.asscalar(pred[-1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
